{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10548be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.analyse\n",
    "import jieba.posseg\n",
    "import jieba.posseg as pseg\n",
    "from neo4j import GraphDatabase\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d0189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "if not all([NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD]):\n",
    "    raise ValueError(\"Missing env vars: NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD\")\n",
    "\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830d7830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1(Finding the Keywords):：use the vocabulary-filtered segmentation approach\n",
    "from pathlib import Path\n",
    "\n",
    "# Load medical vocabulary into a Python set\n",
    "def load_medical_vocab(vocab_dir):\n",
    "    medical_terms = set()\n",
    "    for fname in [\n",
    "        \"vocab.txt\",\n",
    "        \"symptom_vocab.txt\",\n",
    "        \"disease_vocab.txt\",\n",
    "        \"complications_vocab.txt\",\n",
    "        \"alias_vocab.txt\",\n",
    "    ]:\n",
    "        with open(Path(vocab_dir) / fname, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                term = line.strip()\n",
    "                if term:\n",
    "                    medical_terms.add(term)\n",
    "    return medical_terms\n",
    "\n",
    "#   Extract medical-related keywords from a sentence.\n",
    "def key_word(sentence):\n",
    "    medical_terms = load_medical_vocab(\"data/vocab\")\n",
    "    tokens = jieba.lcut(sentence)\n",
    "    return [w for w in tokens if w in medical_terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be0e54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2(Finding the Keywords): perform unsupervised keyword discovery by combining TF–IDF-based and TextRank-based extraction methods and returning the union of their results\n",
    "\n",
    "jieba.Tokenizer()\n",
    "jieba.load_userdict('/vocab.txt')\n",
    "jieba.load_userdict('/symptom_vocab.txt')\n",
    "jieba.load_userdict('/disease_vocab.txt')\n",
    "jieba.load_userdict('/complications_vocab.txt')\n",
    "jieba.load_userdict('/alias_vocab.txt')\n",
    "\n",
    "\n",
    "def keyword(sentence):\n",
    "    entities1=jieba.analyse.extract_tags(sentence, topK=20, withWeight=False)\n",
    "    lists_of_t=jieba.analyse.textrank(sentence, topK=20, withWeight=True)\n",
    "    entities2 = [t[0] for t in lists_of_t]\n",
    "    entities = list(set(entities1+entities2))\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ee1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "\n",
    "model_dir = \"facebook/bart-large-mnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "classifier = pipeline(\"zero-shot-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "candidate_labels = [\n",
    "    \"部门\", \"身体部位\", \"传染性\", \"人群\", \"保险\", \"药物\", \"别名\", \"花费\",\n",
    "    \"治愈率\", \"症状\", \"治疗方案\", \"检查项目\", \"并发症\", \"时间\", \"病症名称\",\n",
    "    \"非医疗/其他\"  \n",
    "]\n",
    "\n",
    "# Internal intent codes used in your system (must align index-wise)\n",
    "intention = [\n",
    "    \"department\", \"part\", \"infection\", \"age\", \"insurance\", \"drug\", \"alias\", \"cost\",\n",
    "    \"rate\", \"symptom\", \"treatment\", \"checklist\", \"complication\", \"period\", \"Disease\",\n",
    "    \"out_of_scope\"\n",
    "]\n",
    "\n",
    "\n",
    "def find_intention(sentence, intent_threshold=0.45, margin_threshold=0.08, oos_threshold=0.50):\n",
    "\n",
    "    result = classifier(sentence, candidate_labels)\n",
    "    labels = result[\"labels\"]\n",
    "    scores = result[\"scores\"]\n",
    "\n",
    "    top_label = labels[0]\n",
    "    top_score = float(scores[0])\n",
    "    second_score = float(scores[1]) if len(scores) > 1 else 0.0\n",
    "    gap = top_score - second_score\n",
    "\n",
    "    # Case A: explicitly out-of-scope\n",
    "    if top_label == \"非医疗/其他\" and top_score >= oos_threshold:\n",
    "        return \"out_of_scope\"\n",
    "\n",
    "    # Map to internal intent code\n",
    "    intent = intention[candidate_labels.index(top_label)]\n",
    "\n",
    "    # Case B: conservative fallback to out-of-scope when classification is unreliable\n",
    "    if top_score < intent_threshold or gap < margin_threshold:\n",
    "        return \"out_of_scope\"\n",
    "\n",
    "    return intent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbdbade",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISEASE_ANCHOR_LABELS = [\n",
    "    \"Disease\",     \n",
    "    \"alias\",       \n",
    "    \"part\",        \n",
    "    \"department\",  \n",
    "    \"symptom\",     \n",
    "    \"drug\",        \n",
    "]\n",
    "\n",
    "#Retrieve all labels for nodes whose name matches the given entity.\n",
    "def fetch_labels(tx, name):\n",
    "    query = \"MATCH (n {name: $name}) RETURN labels(n) AS labels\"\n",
    "    result = tx.run(query, name=name)\n",
    "    all_labels = set()\n",
    "    found = False\n",
    "\n",
    "    for record in result:\n",
    "        found = True\n",
    "        for lab in record[\"labels\"]:\n",
    "            all_labels.add(lab)\n",
    "    return list(all_labels) if found else None\n",
    "\n",
    "\n",
    "# Ground extracted entities in the KG and infer their semantic labels.\n",
    "# Returns situation codes for ambiguity/empty/attribute-only cases.\n",
    "def discover_labels(entities):\n",
    "    label_dic = {}     \n",
    "    hit_any = False\n",
    "\n",
    "    with graph.session() as session:\n",
    "        for entity in entities:\n",
    "            labels = session.execute_read(fetch_labels, entity)\n",
    "\n",
    "            if labels is None:\n",
    "                continue\n",
    "\n",
    "            hit_any = True\n",
    "\n",
    "            # situation 1: ambiguous semantic type\n",
    "            # Here \"multiple labels\" means the entity cannot be uniquely typed for routing.\n",
    "            if len(labels) > 1:\n",
    "                return \"situation 1\"\n",
    "\n",
    "            # exactly one label case\n",
    "            label = labels[0]\n",
    "            label_dic.setdefault(label, []).append(entity)\n",
    "\n",
    "    # situation 2: no entity hits the KG\n",
    "    if not hit_any:\n",
    "        return \"situation 2\"\n",
    "\n",
    "    # situation 3: only attribute-like labels, i.e., cannot anchor disease resolution\n",
    "    if label_dic:\n",
    "        found_anchor = any(label in DISEASE_ANCHOR_LABELS for label in label_dic)\n",
    "        if not found_anchor:\n",
    "            return \"situation 3\"\n",
    "        \n",
    "    return label_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64445056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the names of nodes that are connected to a specified end node by traversing a given relationship.\n",
    "def fetch_related_nodes(tx, end_label, relationship, start_label, end_node_name):\n",
    "    query = f\"\"\"MATCH (start:{start_label})-[r:{relationship}]->(end:{end_label}{{name: $end_node_name}}) RETURN start.name AS related_node_name\"\"\"\n",
    "    result = tx.run(query, end_node_name=end_node_name)\n",
    "    related_node_names = [record[\"related_node_name\"] for record in result]\n",
    "    return related_node_names if related_node_names else None\n",
    "\n",
    "def get_related_nodes(driver, end_label, relationship, start_label, end_node_name):\n",
    "    with driver.session() as session:\n",
    "        return session.execute_read(fetch_related_nodes, end_label, relationship, start_label, end_node_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6cd5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the value of a specified property from a given node.\n",
    "def fetch_property_value(tx, label, name_property, name_value, property_key):\n",
    "    query = f\"\"\"MATCH (n:{label}) WHERE n.{name_property}='{name_value}' RETURN n.{property_key} AS property_values\"\"\"\n",
    "    result = tx.run(query, name_value=name_value)\n",
    "    property_values =[record[\"property_values\"] for record in result]\n",
    "    return property_values if property_values else None\n",
    "\n",
    "def get_property_value(driver, label, name_property, name_value, property_key):\n",
    "    with driver.session() as session:\n",
    "        return session.execute_read(fetch_property_value, label, name_property, name_value, property_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a known node (should be a Disease) and a relationship type, retrieve the connected nodes from the Neo4j knowledge graph.\n",
    "def fetch_end_nodes(tx, start_label, relationship, end_label, start_node_name):\n",
    "    query = f\"\"\"MATCH (start:{start_label} {{name: $start_node_name}})-[r:{relationship}]->(end:{end_label}) RETURN end.name AS related_node_name\"\"\"\n",
    "    result = tx.run(query, start_node_name=start_node_name)\n",
    "    related_node_names = [record[\"related_node_name\"] for record in result]\n",
    "    return related_node_names if related_node_names else None\n",
    "\n",
    "def get_end_nodes(driver, start_label, relationship, end_label, start_node_name):\n",
    "    with driver.session() as session:\n",
    "        return session.execute_read(fetch_end_nodes, start_label, relationship, end_label, start_node_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ff0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map grounded entities to candidate diseases.\n",
    "def disease_search(key_labels):\n",
    "    \"\"\"\n",
    "    Design notes:\n",
    "    - Complications are modeled as Disease nodes (i.e., no separate 'complication' label is required).\n",
    "    - Non-disease entities (symptom/drug/department/etc.) are mapped back to Disease via KG relationships.\n",
    "    - Attribute-only intents (age/infection/insurance/cost/...) cannot infer a disease by themselves.\n",
    "    - Input contains exactly one label with one or more keywords. (assumed by previous steps)\n",
    "    - Return the intersection across all keyword-supported disease sets (diseases supported by every keyword).\n",
    "    \"\"\"\n",
    "\n",
    "    # These labels represent entity types that can be traced back to Disease via graph traversal.\n",
    "    ENTITY_TO_DISEASE_REL = {\n",
    "        \"alias\": \"病症别名\",\n",
    "        \"part\": \"病痛的部位\",\n",
    "        \"department\": \"疾病所属部门\",\n",
    "        \"symptom\": \"疾病症状\",\n",
    "        \"drug\": \"疾病所需药物\",\n",
    "    }\n",
    "    \n",
    "    disease_sets = []\n",
    "    \n",
    "    # Extract the single label and its keywords\n",
    "    (label, keywords), = key_labels.items()\n",
    "    keywords = [k for k in keywords if k]\n",
    "    \n",
    "    # If the single label is Disease, then the keywords themselves are diseases.\n",
    "    # For multiple diseases, the \"intersection\" is only meaningful if they are identical.\n",
    "    if label == \"Disease\":\n",
    "        return sorted(set(keywords))  # keep as candidates; disambiguate upstream if >1\n",
    "    \n",
    "    rel = LABEL_TO_REL[label]\n",
    "\n",
    "    # Build disease sets per keyword, then hard-intersect them.\n",
    "    intersection = None\n",
    "\n",
    "    for kw in keywords:\n",
    "        # Reverse lookup: find diseases.\n",
    "        related = get_related_nodes(graph, label, rel, \"Disease\", kw)\n",
    "        disease_set = set(related) if related else set()\n",
    "\n",
    "        if intersection is None:\n",
    "            intersection = disease_set\n",
    "        else:\n",
    "            intersection &= disease_set\n",
    "\n",
    "        # Early stop: once empty, no disease satisfies all keywords\n",
    "        if not intersection:\n",
    "            return []\n",
    "\n",
    "    return sorted(intersection) if intersection is not None else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f028401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output templated answer, 'we found that your are asking for disease XXX, and the information you want to know about this is XXX'\n",
    "def _missing():\n",
    "    # EN: Sorry, the answer is missing in the knowledge graph.\n",
    "    return \"抱歉，答案缺失\"\n",
    "\n",
    "def _format_list(items):\n",
    "    # Join list items using Chinese separator\n",
    "    return \"、\".join(items) + \"。\"\n",
    "\n",
    "# Relation-based intentions\n",
    "# These intents require traversing edges in the knowledge graph.\n",
    "RELATION_INTENTS = {\n",
    "    \"alias\":       (\"病症别名\", \"alias\",        \"{d}的别名是{a}\"), # EN: Query disease aliases (synonyms)\n",
    "    \"part\":        (\"病痛的部位\", \"part\",        \"{d}病痛的部位是{a}\"), # EN: Query affected body parts\n",
    "    \"department\":  (\"疾病所属部门\", \"department\",\"{d}应该去{a}挂号\"), # EN: Query the clinical department to visit\n",
    "    \"symptom\":     (\"疾病症状\", \"symptom\",      \"{d}的症状有{a}\"), # EN: Query disease symptoms\n",
    "    \"drug\":        (\"疾病所需药物\", \"drug\",      \"{d}的治疗药物是{a}\"), # EN: Query commonly used medications\n",
    "    \"complication\":(\"疾病并发症\", \"Disease\",    \"{d}的并发症是{a}\"), # EN: Query disease complications\n",
    "}\n",
    "\n",
    "# Property-based intentions\n",
    "# These intents correspond to attributes of the Disease node.\n",
    "PROPERTY_INTENTS = {\n",
    "    \"age\":       \"{a}是得{d}的高风险人群。\", # EN: Query high-risk age groups or populations\n",
    "    \"infection\": \"{d}{a}\", # EN: Query whether the disease is infectious \n",
    "    \"insurance\": \"{d}{a}\", # EN: Query whether the disease is covered by health insurance\n",
    "    \"treatment\": \"{d}的治疗方案是{a}\", # EN: Query treatment approaches\n",
    "    \"period\":    \"{d}的治疗时长是{a}\", # EN: Query expected treatment duration\n",
    "    \"rate\":      \"{d}的治愈率是{a}\", # EN: Query cure / remission rate\n",
    "    \"checklist\": \"{d}需要检查{a}\", # EN: Query recommended medical tests\n",
    "    \"cost\":      \"治疗{d}的花费是{a}\", # EN: Query treatment cost\n",
    "}\n",
    "\n",
    "\n",
    "def find_final_answer(given_entity, want_to_know):\n",
    "    # EN: Detected disease: X.\n",
    "    prefix = f\"检测到您提问的疾病为：{given_entity}。\"\n",
    "\n",
    "    # Intent: only confirm the disease name\n",
    "    if want_to_know == \"Disease\":\n",
    "        return prefix\n",
    "\n",
    "    # A) Relation-based intents\n",
    "    if want_to_know in RELATION_INTENTS:\n",
    "        rel_type, end_label, template = RELATION_INTENTS[want_to_know]\n",
    "\n",
    "        # Query neighbor nodes\n",
    "        answer = get_end_nodes(graph, \"Disease\", rel_type, end_label, given_entity)\n",
    "        if not answer:\n",
    "            return _missing()\n",
    "\n",
    "        # Formatting: department reads better without an extra \"。\"\n",
    "        if want_to_know == \"department\":\n",
    "            formatted = \"、\".join(answer)\n",
    "        else:\n",
    "            formatted = _format_list(answer)\n",
    "\n",
    "        return prefix + template.format(d=given_entity, a=formatted)\n",
    "\n",
    "    # B) Property-based intentions\n",
    "    elif want_to_know in PROPERTY_INTENTS:\n",
    "        template = PROPERTY_INTENTS[want_to_know]\n",
    "\n",
    "        # Retrieve property value from the Disease node\n",
    "        answer = get_property_value(graph, \"Disease\", \"name\", given_entity, want_to_know)\n",
    "        if not answer:\n",
    "            return _missing()\n",
    "\n",
    "        # Unified formatting for all properties\n",
    "        formatted = _format_list(answer)\n",
    "\n",
    "        return prefix + template.format(d=given_entity, a=formatted)\n",
    "\n",
    "\n",
    "    # EN: This intent is not supported yet. Please ask about symptoms/treatment/tests/department, etc.\n",
    "    return \"暂不支持该类型的问题。请尝试询问：症状、治疗、检查、科室等。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd0fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handles special cases such as ambiguity, irrelevance, or multiple diseases. Or output the answer\n",
    "def get_answer(sentence):\n",
    "    entities=key_word(sentence)\n",
    "    key_labels=discover_labels(entities)\n",
    "    if key_labels=='situation 1':\n",
    "        # English: Some detected keywords correspond to multiple semantic types in the knowledge graph and require disambiguation. Please provide additional context or clarify whether you are referring to a disease, symptom, medication, or medical examination.\n",
    "        return '检测到部分关键词在知识图谱中存在多种语义类型（需要消歧）。请补充上下文或明确您指的是疾病/症状/药物/检查中的哪一种。' \n",
    "    elif key_labels=='situation 2':\n",
    "        # English: No medical-related keywords were identified in the question. Please provide a disease name, symptom, or medical test (e.g., fever, cough, ALS).\n",
    "        return '未识别到与医疗相关的关键词。请提供疾病名称、症状或检查项目（例如：发热、咳嗽、渐冻症）。' #\n",
    "    elif key_labels == 'situation 3':\n",
    "        # English: Medical-related information was detected, but the identified keywords correspond only to attribute-level information and cannot be used to locate a specific disease. Please provide a disease name, symptom, or medication to continue.\n",
    "        return '已识别到部分医疗相关信息，但这些关键词仅对应属性类信息，无法定位到具体疾病。请补充疾病名称、症状或用药信息以便继续查询。'\n",
    "    else:\n",
    "        t_disease=disease_search(key_labels)\n",
    "        if len(t_disease)>1:\n",
    "            # English: Your question appears to involve multiple diseases: … Please specify which disease you would like to focus on, and I will continue querying and answering based on that disease.\n",
    "            return '检测到您的问题涉及多个疾病，分别是'+t_disease.join(\"，\")+'，请告知您想优先了解哪一个疾病，我将为该疾病继续查询并回答。'\n",
    "        elif len(t_disease)==0:\n",
    "            # English: Your question cannot be resolved to a single disease, possibly because it involves multiple diseases.\n",
    "            return '检测到您的问题无法锁定一个问题，可能因为涉及多个疾病。'\n",
    "        else:\n",
    "            intention = find_intention(sentence)\n",
    "                if intention == 'out_of_scope':\n",
    "                    # English: The question is considered out of scope because it does not involve medical-related information that the system can answer.\n",
    "                    return '您的问题与医疗健康无关，当前系统仅支持回答疾病、症状、用药及相关医疗问题。'\n",
    "            reply=find_final_answer(t_disease[0], intention)\n",
    "            return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a62434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input questions\n",
    "def main():\n",
    "    while True:\n",
    "        question = input(\"请问您有什么问题？\") # English: \"What question would you like to ask?\"\n",
    "        if not question.strip():\n",
    "            print(\"请输入有效的问题。\") # English: \"Please enter a valid question.\"\n",
    "            continue\n",
    "        if question.strip() == \"退出\": # English: \"exit / quit\"\n",
    "            print(\"再见！！！\") # English: \"Goodbye!\"\n",
    "            break\n",
    "        try:\n",
    "            answer = get_answer(question)\n",
    "            print(answer)\n",
    "        except Exception as e:\n",
    "            print(\"系统暂时无法处理该问题，请稍后再试。\") # English: \"The system cannot process this question at the moment. Please try again later.\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a819088e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66325665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
